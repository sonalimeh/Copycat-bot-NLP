{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP Project.ipynb",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "14953093-2abe-458c-aed9-d6db3f470a68",
        "id": "se0Fg6we5zLz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('brown')\n",
        "from nltk.corpus import brown\n",
        "from gensim.models import Word2Vec\n",
        "import multiprocessing\n",
        "corpus=brown.sents()\n",
        "import numpy as np\n",
        "import random\n",
        "import sys"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AMHH5zdo5yoG",
        "colab": {}
      },
      "source": [
        "emb_dim=300\n",
        "wv= Word2Vec(corpus, size=emb_dim, sg=1, window=5, min_count=5, negative=15, iter=10, workers=multiprocessing.cpu_count())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "895b59c6-4a19-4923-8076-e383e954a1b4",
        "id": "Pl5zdO6F5xtu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "f=wv.most_similar(positive=['car'], topn=5)\n",
        "k=f[0][0]\n",
        "#print(k)"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUDnFnbs6A8x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5e151559-c347-4705-e5de-9f50d1d8bb30"
      },
      "source": [
        "sen=wv.predict_output_word(k)\n",
        "sent=str()\n",
        "p=0\n",
        "for i in sen:\n",
        "  p=p+1\n",
        "  if(p==6):\n",
        "    sent=sent+k+' '\n",
        "  sent=sent+i[0]+' '\n",
        "sent"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'then P T A pencil truck single Q on line at '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDZnpmEXHwTU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text=brown.words()\n",
        "text=' '.join(text)\n",
        "text=text.lower()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNBbGigffP5-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "cd98934a-e11c-4700-8229-9f63f6cf710a"
      },
      "source": [
        "chars = sorted(list(set(text))) # getting all unique chars\n",
        "print('total chars: ', len(chars))\n",
        "print(chars)\n",
        "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
        "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
        "print(len(chars))"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total chars:  58\n",
            "[' ', '!', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', '[', ']', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '{', '}']\n",
            "58\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5aFuTQkTbBH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "maxlen = 40\n",
        "step = 3\n",
        "sentences = []\n",
        "next_chars = []\n",
        "for i in range(0, len(text) - maxlen, step):\n",
        "    sentences.append(text[i: i + maxlen])\n",
        "    next_chars.append(text[i + maxlen])\n",
        "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
        "for i, sentence in enumerate(sentences):\n",
        "    for t, char in enumerate(sentence):\n",
        "        x[i, t, char_indices[char]] = 1\n",
        "    y[i, char_indices[next_chars[i]]] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sboejpQTjnG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
        "model.add(Dense(len(chars)))\n",
        "model.add(Activation('softmax'))\n",
        "optimizer = RMSprop(lr=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtiZhURITwEv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.callbacks import LambdaCallback\n",
        "def sample(preds, temperature=1.0):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)\n",
        "def on_epoch_end(epoch, logs):\n",
        "    # Function invoked at end of each epoch. Prints generated text.\n",
        "    print()\n",
        "    print('----- Generating text after Epoch: %d' % epoch)\n",
        "\n",
        "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
        "        print('----- diversity:', diversity)\n",
        "\n",
        "        generated = ''\n",
        "        sentence = text[start_index: start_index + maxlen]\n",
        "        generated += sentence\n",
        "        print('----- Generating with seed: \"' + sentence + '\"')\n",
        "        sys.stdout.write(generated)\n",
        "\n",
        "        for i in range(400):\n",
        "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "            for t, char in enumerate(sentence):\n",
        "                x_pred[0, t, char_indices[char]] = 1.\n",
        "\n",
        "            preds = model.predict(x_pred, verbose=0)[0]\n",
        "            next_index = sample(preds, diversity)\n",
        "            next_char = indices_char[next_index]\n",
        "\n",
        "            generated += next_char\n",
        "            sentence = sentence[1:] + next_char\n",
        "\n",
        "            sys.stdout.write(next_char)\n",
        "            sys.stdout.flush()\n",
        "        print()\n",
        "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cout2c6pT0vp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "filepath = \"weights.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss',\n",
        "                             verbose=1, save_best_only=True,\n",
        "                             mode='min')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etCQ-A-oT1xI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.2,\n",
        "                              patience=1, min_lr=0.001)\n",
        "callbacks = [print_callback, checkpoint, reduce_lr]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ocsYw6kT_84",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "669ecba4-80c9-4d4a-b8bc-7e3720298a0b"
      },
      "source": [
        "model.fit(x, y, batch_size=128, epochs=5, callbacks=callbacks)"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "15956/15956 [==============================] - ETA: 0s - loss: 1.6408\n",
            "----- Generating text after Epoch: 0\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \"10 , d is a diagonalizable operator whic\"\n",
            "10 , d is a diagonalizable operator which a state , and the reason and the complation of the problem . the programs , and the proficer . the complication . the state . the straight the provided to the state , and the propertion . the south the form of the state and state . the program . the state . the complication of the new count the proportional programs of the man . she said . `` the state , and the state . the manual man . the prog\n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \"10 , d is a diagonalizable operator whic\"\n",
            "10 , d is a diagonalizable operator which had not a controlled the reason . he some will way . succeed and states black , and it is the longed the one is considerate not opened the same will be disting and a complation for the face , and the barscand . the bartor in the prosponded to and because the proportional proportion in the time the attention account for the compete , because of the such was the provide and a stores . he street . \n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"10 , d is a diagonalizable operator whic\"\n",
            "10 , d is a diagonalizable operator which said and innented as more against it said as enviews assistinced years complation is informity brisker by alto they'd worked will specifuence . people '' dronliance , and mr. wideria appace dome wissign by a only thrown , both other problems grads the get and the competitite withered , or indisticu , of one launtill dorghed conger of froll . said . may and evidently ptaragene . thinkness alereic\n",
            "----- diversity: 1.2\n",
            "----- Generating with seed: \"10 , d is a diagonalizable operator whic\"\n",
            "10 , d is a diagonalizable operator which rush plating . innysistic compariel this tear . no egne and individuated . for dato . affun the whe commun , well veurwhoms throught and ise still support . he'd trac riclions , these reduction aloting . impressions for the sencess ors are protectivity , to able to because of an obquacely necesarslit gowerk cilley than decented forward a study , acrieton , i fear now perfact in aune drobsa 1onre\n",
            "\n",
            "Epoch 00001: loss improved from inf to 1.64081, saving model to weights.hdf5\n",
            "15956/15956 [==============================] - 1424s 89ms/step - loss: 1.6408 - lr: 0.0100\n",
            "Epoch 2/5\n",
            "15956/15956 [==============================] - ETA: 0s - loss: 1.5219\n",
            "----- Generating text after Epoch: 1\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \"ledge , ten miles north of the campus , \"\n",
            "ledge , ten miles north of the campus , and the such and the proved the state and the state , which had been and the company of the first and the fact of the first and many and state , and the fact the state of the state and the state . the state . the and the first and the consider . the confirmed the country . the company and country . the the complete and the state , and the entric and the state of the course and and the state with t\n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \"ledge , ten miles north of the campus , \"\n",
            "ledge , ten miles north of the campus , many the sounds , and event that the english possible and , and any and the confusion who was relations and however , the"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: RuntimeWarning: divide by zero encountered in log\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " english containing the state and store and have been the state who came to extlitie , and in the parales , but the stuble and a companie the man . it is pallan . the original consideration . short of the police , and the coufsing to the sence of bare to the first at the gradul \n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"ledge , ten miles north of the campus , \"\n",
            "ledge , ten miles north of the campus , shown mreshodiels in lack certain . . if he made out . as some up knet of a pulsharely , more on home of the striphed it a company and trues now a nagin concepts of the eyisnegs attentions , when copus af of writing ials when 3 1seasiny , most , felt '' . mollitt from sugner's intession of the fear about finds , with a still for the middle is day and tending , wherefor paying to be jephained aullo\n",
            "----- diversity: 1.2\n",
            "----- Generating with seed: \"ledge , ten miles north of the campus , \"\n",
            "ledge , ten miles north of the campus , trel-equacuon . the far ariling sekrimers in orienan af michwin a . i will too that it his behind with now . antagges the colorgety os . peronan kate ncancille '' only sawh ould inhable democrathet-that that remow germany to hibine , commid , and chotemen : otbon the said 47 . and the attitueols . thecke -' stutunded lobe 1nold a favants posatorions its busines although for the until gress or the \n",
            "\n",
            "Epoch 00002: loss improved from 1.64081 to 1.52194, saving model to weights.hdf5\n",
            "15956/15956 [==============================] - 1479s 93ms/step - loss: 1.5219 - lr: 0.0100\n",
            "Epoch 3/5\n",
            "15956/15956 [==============================] - ETA: 0s - loss: 1.4992\n",
            "----- Generating text after Epoch: 2\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \"nd dissemination of bibliographies and c\"\n",
            "nd dissemination of bibliographies and control . the contrace , and the seemed to the first the pressure and the state of the sections and the committee , the contraces , and the problem to a contemporary and the seemed to the state of the protemning and the program of the sections of the pass and when the committee , and the provide the pression of the man , and the point of the control , the and work and and the state of the strange a\n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \"nd dissemination of bibliographies and c\"\n",
            "nd dissemination of bibliographies and campanion plant . but the expects the fact control to the instant particularly and the the washington to the new and washington on the only were the constant of the mother and made . it is the demand district to the passing stating , interessed and the states had been the political struck of acomed with the expense , in the said the street at the activity of a proposed in the form . the pretty to t\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"nd dissemination of bibliographies and c\"\n",
            "nd dissemination of bibliographies and cashed italsiky warmes lifing they would is sent part chand of too when may conta-notia on la'n't articrats , of the worldolin and prestive acy s-the mestreast with its stillage-siffes left blanes must then been the scientes , the the reace his eklashless in the river to the preteves version that fond-tace yeared that i was ohia of nomborce detail torde feltho was to be nith on nato leadership bagn\n",
            "----- diversity: 1.2\n",
            "----- Generating with seed: \"nd dissemination of bibliographies and c\"\n",
            "nd dissemination of bibliographies and carc membernations . biabo-cy unother degreeswmenests in smath , a from beted folmquessime they represe of it pressedly in grabmate suvedini' hasseswollken soe , mtcomovicals of a satisosly would be reunble mouth as ebaned the irine-night , aclieve to angroy , knnitate humans that all mothing led e'sn't dea is nothing votes hold beard ways by not woumen round , busked as to be the that dia manronin\n",
            "\n",
            "Epoch 00003: loss improved from 1.52194 to 1.49916, saving model to weights.hdf5\n",
            "15956/15956 [==============================] - 1466s 92ms/step - loss: 1.4992 - lr: 0.0100\n",
            "Epoch 4/5\n",
            "15956/15956 [==============================] - ETA: 0s - loss: 1.4912\n",
            "----- Generating text after Epoch: 3\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \" to explain that she was defending you ,\"\n",
            " to explain that she was defending you , and the service , and the many confidency and the significant and the confidency , the support of the state and success , the state of the conception of the sell of the service , the state of the more to have the control and the state of the both the conception of the conception of the success , and in the state of the state of the substantial court . the state of the state of the state of the co\n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \" to explain that she was defending you ,\"\n",
            " to explain that she was defending you , in the condition of the line of his each reading for the state of the pale of activity , and the seat . and profition and sales in the state of the deliver and the nither . in the present and the both . it was a state was come communist and the communist and the talker to be the family community was a most communication of the service , many delight of the beat and one units and shares was seeded\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \" to explain that she was defending you ,\"\n",
            " to explain that she was defending you , in georging '' , life sicheant . in -- indedered with the such singletting and stude burgh in `` the tanogeor ensularyly doffum afished it . herausst again , the most of colorapols sleep , a sharesa night : `` they might no: e whisky , and all his surces lost rrah and toyk's it are one canysing cty . myechp . dinnestred , souting forming a dailed of estimu in gamin infair of domans of own some wr\n",
            "----- diversity: 1.2\n",
            "----- Generating with seed: \" to explain that she was defending you ,\"\n",
            " to explain that she was defending you , o-by sicme . wishill morn dismit thinking is from loxime holy west door juw . flopee applying a honly come , he snots surenindon's reason to ear's doctor -- a sgeale will upsaid . and wadeers of my moment togethe*ad . defryut and brain would byefff seaise radio , and mere fhallptoursor grea-staird that he waous teerdilagers yeah , suichmeding reason . i ordered unsumrix -- once noteletson sheely \n",
            "\n",
            "Epoch 00004: loss improved from 1.49916 to 1.49118, saving model to weights.hdf5\n",
            "15956/15956 [==============================] - 1452s 91ms/step - loss: 1.4912 - lr: 0.0100\n",
            "Epoch 5/5\n",
            "15956/15956 [==============================] - ETA: 0s - loss: 1.5076\n",
            "----- Generating text after Epoch: 4\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \" mother she would look after me on the r\"\n",
            " mother she would look after me on the realized the state of the street of the states . the state of the problem , and the state of the committee the state of the strong , and the construction of the man and the and street , and the area the streets . the man . the street . the state of the state of the reason , the states , the construction of the and the communist , and the service . the state of the probably and the completic , and t\n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \" mother she would look after me on the r\"\n",
            " mother she would look after me on the realing the concern . the on the streets . and the and manious . the resident and a standard . the at the both in the bend , interpretation he life , he had been example and in the states and the policy , the expendent , and her head that the passely , her service the plan because , many and pay on the demanities in the such and works a change and the first of the targen for the common . around the\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \" mother she would look after me on the r\"\n",
            " mother she would look after me on the retietes team thought that i is , of this harloging . you'll amerise four yould '' found the draias as of siaging : , to tricph religis asfirely , out line it for quence attoodnence in organizations place now . `` you , of direct returned by the office whosinstolled with teller e love -- his previous tra . the later by the into the baid and only to raided work on the public in time setrical when he\n",
            "----- diversity: 1.2\n",
            "----- Generating with seed: \" mother she would look after me on the r\"\n",
            " mother she would look after me on the ragical . in the bhing pictivenomed and a pastils flands , in creaf ferts . bus it ( whathertly raying before mittion of wiuthert informient is various so said , siyn . it wurges late gooding at her days and fesla-dalance each , the fi's wozles was berall case woranicy , trifteldized and hyhe was time argumed that i headreiding questions judgnity , decisoral obera by size . for one-spends fired otx\n",
            "\n",
            "Epoch 00005: loss did not improve from 1.49118\n",
            "15956/15956 [==============================] - 1505s 94ms/step - loss: 1.5076 - lr: 0.0100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f39c79c1fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xYe1KJAUEIm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_text(length, diversity):\n",
        "    # Get random starting text\n",
        "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "    generated = ''\n",
        "    sentence = text[start_index: start_index + maxlen]\n",
        "    print(sentence)\n",
        "    generated += sentence\n",
        "    for i in range(length):\n",
        "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "            for t, char in enumerate(sentence):\n",
        "                x_pred[0, t, char_indices[char]] = 1.\n",
        "\n",
        "            preds = model.predict(x_pred, verbose=0)[0]\n",
        "            next_index = sample(preds, diversity)\n",
        "            next_char = indices_char[next_index]\n",
        "\n",
        "            generated += next_char\n",
        "            sentence = sentence[1:] + next_char\n",
        "    return generated"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cOI7r3cUyjV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c3de4494-ad6f-4bd7-9460-97cfc74bd541"
      },
      "source": [
        "print(generate_text(10, 0.2))"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "to aap use jarur de, aur aise react kare\n",
            "to aap use jarur de, aur aise react kare ka karki \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swwuorEyujFf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}